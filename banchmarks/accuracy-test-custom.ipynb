{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start to end test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify device\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before runing this test, please download models from [https://nomeroff.net.ua/models/](https://nomeroff.net.ua/models/) to **./models/** directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries.\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NomeroffNet path\n",
    "NOMEROFF_NET_DIR = os.path.abspath('../')\n",
    "sys.path.append(NOMEROFF_NET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (/mnt/store/nomeroff-net/nomeroff-net/NomeroffNet/tools/../../data/./models/NpPointsCraft/craft_mlt/craft_mlt_25k_2020-02-16.pth)\n",
      "Loading weights of refiner from checkpoint (/mnt/store/nomeroff-net/nomeroff-net/NomeroffNet/tools/../../data/./models/NpPointsCraft/craft_refiner/craft_refiner_CTW1500_2020-02-16.pth)\n"
     ]
    }
   ],
   "source": [
    "from NomeroffNet.BBoxNpPoints import NpPointsCraft, getCvZoneRGB, convertCvZonesRGBtoBGR, reshapePoints\n",
    "npPointsCraft = NpPointsCraft()\n",
    "npPointsCraft.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "from NomeroffNet.YoloV5Detector import Detector\n",
    "\n",
    "detector = Detector()\n",
    "detector.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NomeroffNet.OptionsDetector import OptionsDetector\n",
    "\n",
    "class_region_custom = [\n",
    "            \"xx-unknown\",\n",
    "            \"eu-ua-2015\",\n",
    "            \"eu-ua-2004\",\n",
    "            \"eu-ua-1995\",\n",
    "            \"eu\",\n",
    "            \"xx-transit\",\n",
    "            \"eu-ua-ordlo-dpr\",\n",
    "            \"eu-ua-ordlo-lpr\",\n",
    "            \"su\"\n",
    "        ]\n",
    "\n",
    "optionsDetector = OptionsDetector({'class_region': class_region_custom })\n",
    "optionsDetector.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NomeroffNet.TextDetector import TextDetector\n",
    "textDetector = TextDetector({\n",
    "    \"eu_ua_2004_2015\": {\n",
    "        \"for_regions\": [\"eu_ua_2015\", \"eu_ua_2004\"],\n",
    "        \"model_path\": \"latest\"\n",
    "    },\n",
    "    \"eu_ua_1995\": {\n",
    "        \"for_regions\": [\"eu_ua_1995\"],\n",
    "        \"model_path\": \"latest\"\n",
    "    },\n",
    "    \"eu\": {\n",
    "        \"for_regions\": [\"eu\"],\n",
    "        \"model_path\": \"latest\"\n",
    "    },\n",
    "    \"ru\": {\n",
    "        \"for_regions\": [\"eu-ua-fake-lnr\", \"eu-ua-fake-dnr\"],\n",
    "        \"model_path\": \"latest\" \n",
    "    },\n",
    "    \"su\": {\n",
    "        \"for_regions\": [\"su\"],\n",
    "        \"model_path\": \"latest\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test(dirName, fname, y, min_bbox_acc = 0.5, verbose=0):\n",
    "    nGood = 0\n",
    "    nBad  = 0\n",
    "    img_path = os.path.join(dirName, fname)\n",
    "    if verbose==1:\n",
    "        print(colored(f\"__________ \\t\\t {img_path} \\t\\t __________\", \"blue\"))\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    targetBoxes = detector.detect_bbox(img)\n",
    "    \n",
    "    all_points = npPointsCraft.detect(img, targetBoxes,[5,2,0])\n",
    "    # for  images/14.jpeg bug\n",
    "    all_points = [ps for ps in all_points if len(ps)]\n",
    "    \n",
    "    print('all_points')\n",
    "    print(all_points)\n",
    "    # cut zones\n",
    "    toShowZones = [getCvZoneRGB(img, reshapePoints(rect,1)) for rect in all_points]\n",
    "    zones = convertCvZonesRGBtoBGR(toShowZones)    \n",
    "\n",
    "    # find standart\n",
    "    regionIds, countLines = optionsDetector.predict(zones)\n",
    "    regionNames = optionsDetector.getRegionLabels(regionIds)\n",
    "    print(regionNames)\n",
    "    print(countLines)\n",
    "    \n",
    "    for zone, points in zip(toShowZones, all_points):\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(zone)\n",
    "        plt.show()\n",
    "\n",
    "    # find text with postprocessing by standart  \n",
    "    textArr = textDetector.predict(zones, regionNames, countLines)\n",
    "    print(textArr)\n",
    "    \n",
    "     # draw rect and 4 points\n",
    "    for targetBox, points in zip(targetBoxes, all_points):\n",
    "        # draw \n",
    "        cv2.rectangle(img, \n",
    "                      (int(targetBox[0]), int(targetBox[1])), \n",
    "                      (int(targetBox[2]), int(targetBox[3])), \n",
    "                      (0,120,255), \n",
    "                      3)\n",
    "        #print(points, points.shape)\n",
    "        cv2.polylines(img, np.array([points], np.int32), True, (255,120,255),3)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    for yText in y:\n",
    "        if yText in textArr:\n",
    "            print(colored(f\"OK: TEXT:{yText} \\t\\t\\t RESULTS:{textArr} \\n\\t\\t\\t\\t\\t in PATH:{img_path}\", 'green'))\n",
    "            nGood += 1\n",
    "        else:\n",
    "            print(colored(f\"NOT OK: TEXT:{yText} \\t\\t\\t RESULTS:{textArr} \\n\\t\\t\\t\\t\\t in PATH:{img_path} \", 'red'))\n",
    "            nBad += 1\n",
    "    return nGood, nBad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = \"./images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testData = {\n",
    "    \"0.jpeg\": [\"AI5255EI\"],\n",
    "    \"1.jpeg\": [\"AT6883CM\"],\n",
    "    \"2.jpeg\": [\"AT1515CK\"],\n",
    "    \"3.jpeg\": [\"BX0578CE\"],\n",
    "    \"4.jpeg\": [\"AC4249CB\"],\n",
    "    \"5.jpeg\": [\"BC3496HC\"],\n",
    "    \"6.jpeg\": [\"BC3496HC\"],\n",
    "    \"7.jpeg\": [\"AO1306CH\"],\n",
    "    \"8.jpeg\": [\"AE1077CO\"],\n",
    "    \"9.jpeg\": [\"AB3391AK\"],\n",
    "    \"10.jpeg\": [\"BE7425CB\"],\n",
    "    \"11.jpeg\": [\"BE7425CB\"],\n",
    "    \"12.jpeg\": [\"AB0680EA\"],\n",
    "    \"13.jpeg\": [\"AB0680EA\"],\n",
    "    \"14.jpeg\": [\"BM1930BM\"],\n",
    "    \"15.jpeg\": [\"AI1382HB\"],\n",
    "    \"16.jpeg\": [\"AB7333BH\"],\n",
    "    \"17.jpeg\": [\"AB7642CT\"],\n",
    "    \"18.jpeg\": [\"AC4921CB\"],\n",
    "    \"19.jpeg\": [\"BC9911BK\"],\n",
    "    \"20.jpeg\": [\"BC7007AK\"],\n",
    "    \"21.jpeg\": [\"AB5649CI\"],\n",
    "    \"22.jpeg\": [\"AX2756EK\"],\n",
    "    \"23.jpeg\": [\"AA7564MX\"],\n",
    "    \"24.jpeg\": [\"AM5696CK\"],\n",
    "    \"25.jpeg\": [\"AM5696CK\"],\n",
    "}\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"]  = (20, 20)    \n",
    "\n",
    "gGood = 0\n",
    "gBad = 0\n",
    "i = 0\n",
    "for fileName in testData.keys():\n",
    "    nGood, nBad = await test(dirName, fileName, testData[fileName], verbose=1)\n",
    "    gGood += nGood\n",
    "    gBad += nBad\n",
    "    i += 1\n",
    "total = gGood + gBad\n",
    "print(f\"TOTAL GOOD: {gGood/total}\")\n",
    "print(f\"TOTAL BED: {gBad/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}