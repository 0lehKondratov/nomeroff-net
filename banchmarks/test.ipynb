{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start to end test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before runing this test, please download models from [https://nomeroff.net.ua/models/](https://nomeroff.net.ua/models/) to **./models/** directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "from termcolor import colored\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# change this property\n",
    "NOMEROFF_NET_DIR = os.path.abspath('../')\n",
    "\n",
    "# specify the path to Mask_RCNN if you placed it outside Nomeroff-net project\n",
    "MASK_RCNN_DIR = os.path.join(NOMEROFF_NET_DIR, 'Mask_RCNN')\n",
    "\n",
    "MASK_RCNN_LOG_DIR = os.path.join(NOMEROFF_NET_DIR, 'logs')\n",
    "MASK_RCNN_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \"models/mask_rcnn_numberplate_0700.h5\")\n",
    "OPTIONS_MODEL_PATH =  os.path.join(NOMEROFF_NET_DIR, \"models/numberplate_options_2019_03_05.h5\")\n",
    "\n",
    "mode =  \"cpu\"\n",
    "OCR_NP_UKR_TEXT =  os.path.join(NOMEROFF_NET_DIR, \"models/anpr_ocr_ua_12-{}.h5\".format(mode))\n",
    "OCR_NP_EU_TEXT =  os.path.join(NOMEROFF_NET_DIR, \"models/anpr_ocr_eu_2-{}.h5\".format(mode))\n",
    "OCR_NP_RU_TEXT =  os.path.join(NOMEROFF_NET_DIR, \"models/anpr_ocr_ru_3-{}.h5\".format(mode))\n",
    "\n",
    "sys.path.append(NOMEROFF_NET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/data/www/nomeroff-net/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from NomeroffNet import  filters, RectDetector, TextDetector, OptionsDetector, Detector, textPostprocessingAsync\n",
    "\n",
    "nnet = Detector(MASK_RCNN_DIR, MASK_RCNN_LOG_DIR)\n",
    "nnet.loadModel(MASK_RCNN_MODEL_PATH)\n",
    "\n",
    "rectDetector = RectDetector()\n",
    "\n",
    "optionsDetector = OptionsDetector()\n",
    "optionsDetector.load(OPTIONS_MODEL_PATH)\n",
    "\n",
    "# Initialize text detector.\n",
    "textDetector = TextDetector({\n",
    "    \"eu_ua_2004_2015\": {\n",
    "        \"for_regions\": [\"eu_ua_2015\", \"eu_ua_2004\"],\n",
    "        \"model_path\": OCR_NP_UKR_TEXT\n",
    "    },\n",
    "    \"eu\": {\n",
    "        \"for_regions\": [\"eu\", \"eu_ua_1995\"],\n",
    "        \"model_path\": OCR_NP_EU_TEXT\n",
    "    },\n",
    "    \"ru\": {\n",
    "        \"for_regions\": [\"ru\"],\n",
    "        \"model_path\": OCR_NP_RU_TEXT\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "async def test(dirName, fname, y, verbose=0, max_img_w = 1280):\n",
    "    img_path = os.path.join(dirName, fname)\n",
    "    if verbose==1:\n",
    "        print(colored(f\"__________ \\t\\t {img_path} \\t\\t __________\", \"blue\"))\n",
    "    img = mpimg.imread(img_path)\n",
    "    nGood = 0\n",
    "    nBad = 0\n",
    "    img_path = os.path.join(dirName, fname)\n",
    "    if verbose:\n",
    "        print(img_path)\n",
    "    img = mpimg.imread(img_path)\n",
    "\n",
    "    # corect size for better speed\n",
    "    img_w = img.shape[1]\n",
    "    img_h = img.shape[0]\n",
    "    img_w_r = 1\n",
    "    img_h_r = 1\n",
    "    if img_w > max_img_w:\n",
    "        resized_img = cv2.resize(img, (max_img_w, int(max_img_w/img_w*img_h)))\n",
    "        img_w_r = img_w/max_img_w\n",
    "        img_h_r = img_h/(max_img_w/img_w*img_h)\n",
    "    else:\n",
    "        resized_img = img\n",
    "\n",
    "    NP = nnet.detect([resized_img]) \n",
    "    \n",
    "    # Generate image mask.\n",
    "    cv_img_masks = await filters.cv_img_mask_async(NP)\n",
    "    \n",
    "    #################################\n",
    "    arrPoints = await rectDetector.detectAsync(cv_img_masks, outboundHeightOffset=3-img_w_r, version=1)\n",
    "    arrPoints[..., 1:2] = arrPoints[..., 1:2]*img_h_r\n",
    "    arrPoints[..., 0:1] = arrPoints[..., 0:1]*img_w_r\n",
    "    toShowZones = rectDetector.get_cv_zonesRGB(img, arrPoints)\n",
    "    if verbose:\n",
    "        print(\"old\")\n",
    "        for zone, points in zip(toShowZones, arrPoints):\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(zone)\n",
    "            plt.show()\n",
    "    ##################################\n",
    "            \n",
    "    # Detect points.\n",
    "    arrPoints = await rectDetector.detectAsync(cv_img_masks, outboundHeightOffset=3-img_w_r, fixGeometry=True, fixRectangleAngle=10)\n",
    "    arrPoints[..., 1:2] = arrPoints[..., 1:2]*img_h_r\n",
    "    arrPoints[..., 0:1] = arrPoints[..., 0:1]*img_w_r\n",
    "    \n",
    "    # cut zones\n",
    "    zones = await rectDetector.get_cv_zonesBGR_async(img, arrPoints)\n",
    "    toShowZones = rectDetector.get_cv_zonesRGB(img, arrPoints)\n",
    "    if verbose:\n",
    "        print(\"new\")\n",
    "        for zone, points in zip(toShowZones, arrPoints):\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(zone)\n",
    "            plt.show()\n",
    "\n",
    "    # find standart\n",
    "    regionIds, stateIds = optionsDetector.predict(zones)\n",
    "    regionNames = optionsDetector.getRegionLabels(regionIds)\n",
    "    if verbose:\n",
    "        print(regionNames)\n",
    "\n",
    "    # find text with postprocessing by standart  \n",
    "    textArr = textDetector.predict(zones, regionNames)\n",
    "    textArr = await textPostprocessingAsync(textArr, regionNames)\n",
    "    if verbose:\n",
    "        print(textArr)\n",
    "    \n",
    "    for yText in y:\n",
    "        if yText in textArr:\n",
    "            print(colored(f\"OK: TEXT:{yText} \\t\\t\\t RESULTS:{textArr} \\n\\t\\t\\t\\t\\t in PATH:{img_path}\", 'green'))\n",
    "            nGood += 1\n",
    "        else:\n",
    "            print(colored(f\"NOT OK: TEXT:{yText} \\t\\t\\t RESULTS:{textArr} \\n\\t\\t\\t\\t\\t in PATH:{img_path} \", 'red'))\n",
    "            nBad += 1\n",
    "    return nGood, nBad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__________ \t\t images/0.jpeg \t\t __________\u001b[0m\n",
      "images/0.jpeg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "detectAsync() got an unexpected keyword argument 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mcell_name\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e0bf04e8d1ca>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(dirName, fname, y, verbose, max_img_w)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0marrPoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mawait\u001b[0m \u001b[0mrectDetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_img_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutboundHeightOffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimg_w_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0marrPoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrPoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_h_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0marrPoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrPoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_w_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: detectAsync() got an unexpected keyword argument 'version'"
     ]
    }
   ],
   "source": [
    "testData = {\n",
    "    \"0.jpeg\": [\"AI5255EI\"],\n",
    "    \"1.jpeg\": [\"HH7777CC\"],\n",
    "    \"2.jpeg\": [\"AT1515CK\"],\n",
    "    \"3.jpeg\": [\"BX0578CE\"],\n",
    "    \"4.jpeg\": [\"AC4249CB\"],\n",
    "    \"5.jpeg\": [\"BC3496HC\"],\n",
    "    \"6.jpeg\": [\"BC3496HC\"],\n",
    "    \"7.jpeg\": [\"AO1306CH\"],\n",
    "    \"8.jpeg\": [\"AE1077CO\"],\n",
    "    \"9.jpeg\": [\"AB3391AK\"],\n",
    "    \"10.jpeg\": [\"BE7425CB\"],\n",
    "    \"11.jpeg\": [\"BE7425CB\"],\n",
    "    \"12.jpeg\": [\"AB0680EA\"],\n",
    "    \"13.jpeg\": [\"AB0680EA\"],\n",
    "    \"14.jpeg\": [\"BM1930BM\"],\n",
    "    \"15.jpeg\": [\"AI1382HB\"],\n",
    "    \"16.jpeg\": [\"AB7333BH\"],\n",
    "    \"17.jpeg\": [\"AB7642CT\"],\n",
    "    \"18.jpeg\": [\"AC4921CB\"],\n",
    "    \"19.jpeg\": [\"BC9911BK\"],\n",
    "    \"20.jpeg\": [\"BC7007AK\"],\n",
    "    \"21.jpeg\": [\"AB5649CI\"],\n",
    "    \"22.jpeg\": [\"AX2756EK\"],\n",
    "    \"23.jpeg\": [\"AA7564MX\"],\n",
    "    \"24.jpeg\": [\"AM5696CK\"],\n",
    "    \"25.jpeg\": [\"AM5696CK\"],\n",
    "}\n",
    "\n",
    "gGood = 0\n",
    "gBad = 0\n",
    "i = 0\n",
    "for fileName in testData.keys():\n",
    "    nGood, nBad = await test(dirName, fileName, testData[fileName], verbose=1)\n",
    "    gGood += nGoodfixRectangleAngle\n",
    "    gBad += nBad\n",
    "    i += 1\n",
    "total = gGood + gBad\n",
    "print(f\"TOTAL GOOD: {gGood/total}\")\n",
    "print(f\"TOTAL BED: {gBad/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await test(dirName, \"6.jpeg\", [\"BC3496HC\"], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
