{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from _paths import nomeroff_net_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# auto download latest dataset\n",
    "from nomeroff_net.tools import modelhub\n",
    "\n",
    "# auto download latest dataset\n",
    "#info = modelhub.download_dataset_for_model(\"EuUa1995\")\n",
    "#PATH_TO_DATASET = info[\"dataset_path\"]\n",
    "PATH_TO_DATASET = os.path.join(nomeroff_net_dir, \"data/dataset/TextDetector/ocr_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(model_path='latest',\n",
    "           text_detector_name = \"eu_ua_1995\",\n",
    "           img_format = \"png\",\n",
    "           root_dir=os.path.join(PATH_TO_DATASET, \"test\"),\n",
    "           predicted_part_size=1,\n",
    "           acc_less_than = 0.7,\n",
    "           replace_tamplate = {'moderation': {'isModerated': 1, 'moderatedBy': 'ApelSYN'}}):\n",
    "    text_detector_module = importlib.import_module(\"nomeroff_net.TextDetectors.\"+text_detector_name)\n",
    "    text_detector = getattr(text_detector_module, text_detector_name)\n",
    "    text_detector.load(model_path)\n",
    "\n",
    "    ann_dir = os.path.join(root_dir, \"ann\")\n",
    "    jsons = []\n",
    "    jsons_paths = []\n",
    "    for dir_name, subdir_list, file_list in os.walk(ann_dir):\n",
    "        for fname in file_list:\n",
    "            fname = os.path.join(ann_dir, fname)\n",
    "            jsons_paths.append(fname)\n",
    "            with open(fname) as jsonF:\n",
    "                jsonData = json.load(jsonF)\n",
    "            jsons.append(jsonData)\n",
    "    print(\"LOADED {} ANNOTATIONS\".format(len(jsons)))\n",
    "\n",
    "    img_dir = os.path.join(root_dir, \"img\")\n",
    "    imgs = []\n",
    "    for j in jsons:\n",
    "        img_path =os.path.join(img_dir, \"{}.{}\".format(j[\"name\"], img_format))\n",
    "        img = cv2.imread(img_path)\n",
    "        imgs.append(img)\n",
    "    print(\"LOADED {} IMAGES\".format(len(imgs)))\n",
    "\n",
    "    predicted = []\n",
    "    accs      = []\n",
    "    N = int(len(imgs) / predicted_part_size) + 1\n",
    "    for i in range(N):\n",
    "        part           = i*predicted_part_size\n",
    "        part_imgs      = imgs[part:part+predicted_part_size]\n",
    "        predicted_part, net_out_value_part = text_detector.predict(part_imgs, return_acc=True)\n",
    "        predicted     += predicted_part\n",
    "\n",
    "\n",
    "        # get accuracy\n",
    "        if acc_less_than >= 1:\n",
    "            # not process acc\n",
    "            accs  += [1 for _predicted in predicted_part]\n",
    "            continue\n",
    "        # process accuracy\n",
    "        acc_part = []\n",
    "        for _predicted, _net_out_value in zip(predicted_part, net_out_value_part):\n",
    "            acc = text_detector.get_acc([_net_out_value], [_predicted])\n",
    "            acc_part.append(acc)\n",
    "        accs  += acc_part\n",
    "\n",
    "\n",
    "    print(\"PREDICTED {} IMAGES\".format(len(predicted)))\n",
    "\n",
    "    err_cnt = 0\n",
    "    for i in range(len(jsons_paths)):\n",
    "        json_path      = jsons_paths[i]\n",
    "        predicted_item = predicted[i]\n",
    "        jsonData       = jsons[i]\n",
    "        acc            = accs[i]\n",
    "        jsonData[\"moderation\"][\"predicted\"] = predicted_item\n",
    "\n",
    "        if jsonData[\"description\"].lower() == jsonData[\"moderation\"][\"predicted\"].lower() and acc > acc_less_than:\n",
    "            jsonData[\"moderation\"][\"isModerated\"] = 1\n",
    "        else:\n",
    "            print(\"Predicted '{}' with acc {}, real: '{}' in file {}\".format(\n",
    "                jsonData[\"moderation\"][\"predicted\"].lower(),\n",
    "                acc,\n",
    "                jsonData[\"description\"].lower(),\n",
    "                json_path))\n",
    "            err_cnt = err_cnt+1\n",
    "            jsonData[\"moderation\"][\"isModerated\"] = 0\n",
    "        with open(json_path, \"w\", encoding='utf8') as jsonWF:\n",
    "            json.dump(jsonData, jsonWF,  ensure_ascii=False)\n",
    "\n",
    "    print(\"Error detection count: {}\".format(err_cnt))\n",
    "    print(\"Accuracy: {}\".format(1-err_cnt/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED 1037 ANNOTATIONS\n",
      "LOADED 1037 IMAGES\n",
      "PREDICTED 1037 IMAGES\n",
      "Predicted '3765xm' with acc 0.6398438215255737, real: '33765xm' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/33765XM_8934.json\n",
      "Predicted '25930oa' with acc 0.8893561363220215, real: '25933oa' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/25933OA_17106.json\n",
      "Predicted '06853a' with acc 0.8745327591896057, real: '06853aa' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/06853AA_44563.json\n",
      "Predicted '2593kb' with acc 0.7685607075691223, real: '25933kb' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/25933KB_34225.json\n",
      "Predicted '83104h' with acc 0.7562890648841858, real: '83104hi' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/83104HI_37155.json\n",
      "Predicted '04653oi' with acc 0.8510855436325073, real: '04653ot' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/04653OT_23686.json\n",
      "Predicted '4811ib' with acc 0.6948721408843994, real: '84811ib' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/84811IB_41677.json\n",
      "Predicted '76685aha' with acc 0.996146023273468, real: '76685ha' in file /mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./dataset/TextDetector/EuUa1995/autoriaNumberplateOcrUa-1995-2021-08-25/test/ann/76685MA_35894.json\n",
      "Error detection count: 8\n",
      "Accuracy: 0.9922854387656702\n"
     ]
    }
   ],
   "source": [
    "compare(acc_less_than = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}